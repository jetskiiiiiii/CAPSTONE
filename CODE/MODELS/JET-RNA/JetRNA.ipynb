{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 22:24:46.184376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OneHotEncoding import get_one_hot_sequence\n",
    "from BuildMatrixFromDotBracket import get_couples, build_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2_structure = \"...(((((((..((((((.........))))))......).((((((.......))))))..))))))...\"\n",
    "example_2_sequence = \"CGCUUCAUAUAAUCCUAAUGAUAUGGUUUGGGAGUUUCUACCAAGAGCCUUAAACUCUUGAUUAUGAAGUG\"\n",
    "example_2_length = len(example_2_sequence)\n",
    "\n",
    "# Get one-hot encoded sequence (X) and adjacency matrix (y) of example data\n",
    "example_2_one_hot = get_one_hot_sequence(example_2_sequence)\n",
    "example_2_matrix = build_matrix(get_couples(example_2_structure), example_2_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input layer to accept one-hot encoded sequences\n",
    "input_layer = tf.keras.layers.Input(shape=(example_2_length, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process sequences using an LSTM layer, returning all outputs\n",
    "lstm_layer = tf.keras.layers.LSTM(units=64, return_sequences=True)(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the LSTM output into a 1D vector\n",
    "flattened = tf.keras.layers.Flatten()(lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dense output layer with sigmoid activation for probabilities\n",
    "output_layer = tf.keras.layers.Dense(example_2_length * example_2_length, activation='sigmoid')(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the output into a 2D adjacency matrix\n",
    "adjacency_matrix = tf.reshape(output_layer, (-1, example_2_length, example_2_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the model, specifying input and output layers\n",
    "model = tf.keras.Model(inputs=input_layer, outputs=adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the model for training\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 71, 4)]           0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 71, 64)            17664     \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 4544)              0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 5041)              22911345  \n",
      "                                                                 \n",
      " tf.reshape_13 (TFOpLambda)  (None, 71, 71)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22929009 (87.47 MB)\n",
      "Trainable params: 22929009 (87.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 71, 4) (1, 71, 71)\n"
     ]
    }
   ],
   "source": [
    "# Reshape input data to match model's expected shape\n",
    "example_2_one_hot = example_2_one_hot.reshape(1, 71, 4)\n",
    "print(example_2_one_hot.shape, example_2_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6934 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.6281 - accuracy: 0.4366\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.5551 - accuracy: 0.4366\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.4765 - accuracy: 0.4225\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.3943 - accuracy: 0.4225\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 0.3108 - accuracy: 0.4366\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 0.2295 - accuracy: 0.4366\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 0.1547 - accuracy: 0.4225\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 0.0916 - accuracy: 0.4085\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 0.0451 - accuracy: 0.3944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1334aabd0>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with input and target data for 10 epochs\n",
    "model.fit(example_2_one_hot, example_2_matrix, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
