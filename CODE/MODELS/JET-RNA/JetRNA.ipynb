{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-09 22:24:46.184376: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OneHotEncoding import get_one_hot_sequence, one_hot\n",
    "from BuildMatrixFromDotBracket import get_couples, build_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting input\n",
    "\n",
    "# defining folder path\n",
    "bprna_folder_path = \"../../DATASETS/bpRNA_1m_90/bpRNA_1m_90_DBNFILES_as_TXT/\"\n",
    "pattern = r\"bpRNA_CRW_.*\\.txt$\" # get files that start with \"bpRNA_CRW_\"\n",
    "extracted_data = {}\n",
    "bprna_df = pd.DataFrame(columns=[\"name\", \"length\", \"sequence\", \"dbn\"])\n",
    "\n",
    "# iterate through \n",
    "for filename in os.listdir(bprna_folder_path):\n",
    "    if re.match(pattern, filename):\n",
    "        with open(os.path.join(bprna_folder_path, filename), \"r\") as file:\n",
    "            for i, line in enumerate(file):\n",
    "                if i == 0:\n",
    "                    key, value = line.strip().split(\" \", 1)\n",
    "                    extracted_data[\"name\"] = value\n",
    "                elif i == 1:\n",
    "                    key, value = line.strip().split(\" \", 1)\n",
    "                    extracted_data[\"length\"] = value\n",
    "                elif i == 3:\n",
    "                    extracted_data[\"sequence\"] = line\n",
    "                elif i == 4:\n",
    "                    extracted_data[\"dbn\"] = line\n",
    "        bprna_df = pd.concat([bprna_df, pd.DataFrame([extracted_data])], ignore_index=True)\n",
    "        extracted_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_structure = bprna_df.loc[8, \"dbn\"]\n",
    "example_sequence_length = int(bprna_df.loc[8, \"length\"])\n",
    "example_couples = get_couples(example_structure)\n",
    "example_matrix = build_matrix(example_couples, example_sequence_length)\n",
    "# example_one_hot = get_one_hot_sequence(bprna_df.loc[8, \"sequence\"])\n",
    "example_one_hot = one_hot(bprna_df.loc[8, \"sequence\"])\n",
    "example_one_hot = example_one_hot[:-1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2_structure = \"...(((((((..((((((.........))))))......).((((((.......))))))..))))))...\"\n",
    "example_2_sequence = \"CGCUUCAUAUAAUCCUAAUGAUAUGGUUUGGGAGUUUCUACCAAGAGCCUUAAACUCUUGAUUAUGAAGUG\"\n",
    "example_2_length = len(example_2_sequence)\n",
    "\n",
    "example_2_one_hot = one_hot(example_2_sequence)\n",
    "example_2_matrix = build_matrix(get_couples(example_2_structure), example_2_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n",
      "[[0 1 0 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [1 0 0 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]]\n",
      "370\n"
     ]
    }
   ],
   "source": [
    "print(example_sequence_length)\n",
    "print(example_one_hot)\n",
    "print(len(example_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = get_one_hot_sequence(\"A\")\n",
    "U = get_one_hot_sequence(\"U\")\n",
    "G = get_one_hot_sequence(\"G\")\n",
    "C = get_one_hot_sequence(\"C\")\n",
    "allowed_pairs = [(A, U), (U, A), (G, C), (C, G), (G, U), (U, G)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 4)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_2_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=(71, 4))\n",
    "# input_layer = tf.keras.layers.Input(shape=(None, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = tf.keras.layers.LSTM(units=64, return_sequences=True)(input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = tf.keras.layers.Flatten()(lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_pooled = tf.keras.layers.GlobalMaxPooling1D()(lstm_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = tf.keras.layers.Dense(example_2_length * example_2_length, activation='sigmoid')(flattened)\n",
    "# output_layer = tf.keras.layers.Dense(example_2_length * example_2_length, activation='sigmoid')(global_max_pooled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = tf.reshape(output_layer, (-1, example_2_length, example_2_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input layer for variable-length sequences of one-hot encodings\n",
    "# input_layer = tf.keras.layers.Input(shape=(example_sequence_length, 4))\n",
    "\n",
    "# # Recurrent layer to process sequential information\n",
    "# lstm_layer = tf.keras.layers.LSTM(units=64, return_sequences=True)(input_layer)\n",
    "\n",
    "# flattened = tf.keras.layers.Flatten()(lstm_layer)\n",
    "\n",
    "# # Output layer for adjacency matrix\n",
    "# output_layer = tf.keras.layers.Dense(example_sequence_length * example_sequence_length, activation='sigmoid')(flattened)\n",
    "\n",
    "# # Reshape into adjacency matrix\n",
    "# adjacency_matrix = tf.reshape(output_layer, (-1, example_sequence_length, example_sequence_length))\n",
    "\n",
    "# # Build the model\n",
    "# model = tf.keras.Model(inputs=input_layer, outputs=adjacency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(1, 71, 4)]              0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (1, 71, 64)               17664     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (1, 4544)                 0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (1, 5041)                 22911345  \n",
      "                                                                 \n",
      " tf.reshape_10 (TFOpLambda)  (1, 71, 71)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22929009 (87.47 MB)\n",
      "Trainable params: 22929009 (87.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.expand_dims(np.arange(0, example_2_length, 4), axis=1)\n",
    "# y = np.expand_dimsnp.arange((0, example_2_length, 4), axis=1)\n",
    "# X = tf.stack(example_2_one_hot)\n",
    "# y = tf.stack(example_2_matrix)\n",
    "X = np.array(example_2_one_hot)\n",
    "y = np.array(example_2_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_2_one_hot = example_2_one_hot.reshape(-1, 71, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 1\n  y sizes: 71\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample_2_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_2_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model.fit(X, y, epochs=10)\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/VILLAIN/CAPSTONE/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Volumes/VILLAIN/CAPSTONE/.venv/lib/python3.11/site-packages/keras/src/engine/data_adapter.py:1960\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1953\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1954\u001b[0m         label,\n\u001b[1;32m   1955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1956\u001b[0m             \u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)\n\u001b[1;32m   1957\u001b[0m         ),\n\u001b[1;32m   1958\u001b[0m     )\n\u001b[1;32m   1959\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1960\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 1\n  y sizes: 71\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(example_2_one_hot, example_2_matrix, epochs=10)\n",
    "# model.fit(X, y, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
